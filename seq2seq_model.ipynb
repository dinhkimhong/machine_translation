{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACHINE TRANSLATION MODEL - SEQ2SEQ MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I'm going to build Seq2Seq Model to translate English sentences to French sentences.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the work pipeline:\n",
    "1. Read data from txt files and split into train and test dataframe\n",
    "2. Tokenize sentences and transform to one hot encode sequence data\n",
    "3. Build model using GRU, RepeatVector\n",
    "4. Predict on test data/ Translate English sentences in test data\n",
    "5. Evaluate the model using BLEU score (future work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>french_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
       "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the united states is usually chilly during jul...</td>\n",
       "      <td>les états-unis est généralement froid en juill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california is usually quiet during march , and...</td>\n",
       "      <td>california est généralement calme en mars , et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the united states is sometimes mild during jun...</td>\n",
       "      <td>les états-unis est parfois légère en juin , et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your least liked fruit is the grape , but my l...</td>\n",
       "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    english_sentence  \\\n",
       "0  new jersey is sometimes quiet during autumn , ...   \n",
       "1  the united states is usually chilly during jul...   \n",
       "2  california is usually quiet during march , and...   \n",
       "3  the united states is sometimes mild during jun...   \n",
       "4  your least liked fruit is the grape , but my l...   \n",
       "\n",
       "                                     french_sentence  \n",
       "0  new jersey est parfois calme pendant l' automn...  \n",
       "1  les états-unis est généralement froid en juill...  \n",
       "2  california est généralement calme en mars , et...  \n",
       "3  les états-unis est parfois légère en juin , et...  \n",
       "4  votre moins aimé fruit est le raisin , mais mo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sents = list()\n",
    "with open('vocab_en.txt', encoding='utf-8') as txt_file:\n",
    "    for line in txt_file:\n",
    "        new_line = line.rstrip('\\n')\n",
    "        en_sents.append(new_line)\n",
    "\n",
    "fr_sents = list()\n",
    "with open('vocab_fr.txt', encoding='utf-8') as txt_file:\n",
    "    for line in txt_file.readlines():\n",
    "        new_line = line.rstrip('\\n')\n",
    "        fr_sents.append(new_line)\n",
    "        \n",
    "df = pd.DataFrame({'english_sentence':en_sents, 'french_sentence': fr_sents})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 137860 entries, 0 to 137859\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   english_sentence  137860 non-null  object\n",
      " 1   french_sentence   137860 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 64874,  19114,  22771, ...,  23172, 123966, 106799], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle indicies\n",
    "indicies = np.array(df.index)\n",
    "np.random.shuffle(indicies)\n",
    "indicies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train (80% data) and test dataframe (20% data) after shuffling rows by indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, test_size = int((len(df)/10) * 8), int((len(df)/10) * 2)\n",
    "train_indicies, test_indicies = indicies[:train_size], indicies[train_size:]\n",
    "\n",
    "train_df = df.iloc[train_indicies, :]\n",
    "test_df = df.iloc[test_indicies, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenize sentences then transform to one hot encode sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, GRU, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_token = Tokenizer()\n",
    "en_token.fit_on_texts(train_df['english_sentence'])\n",
    "\n",
    "fr_token = Tokenizer()\n",
    "fr_token.fit_on_texts(train_df['french_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_index_to_word = en_token.index_word\n",
    "fr_index_to_word = fr_token.index_word\n",
    "\n",
    "en_word_to_index = en_token.word_index\n",
    "fr_word_to_index = fr_token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_index_to_word[0] = 'Unknown'\n",
    "fr_index_to_word[0] = 'Unknown'\n",
    "\n",
    "en_word_to_index['Unknown'] = 0\n",
    "fr_word_to_index['Unknown'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 21\n"
     ]
    }
   ],
   "source": [
    "max_en_len = max([len(i) for i in en_token.texts_to_sequences(train_df['english_sentence'])])\n",
    "max_fr_len = max([len(i) for i in fr_token.texts_to_sequences(train_df['french_sentence'])])\n",
    "print(max_en_len, max_fr_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 342\n"
     ]
    }
   ],
   "source": [
    "en_vocab = len(en_token.index_word)\n",
    "fr_vocab = len(fr_token.index_word)\n",
    "print(en_vocab, fr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200) (342, 342)\n"
     ]
    }
   ],
   "source": [
    "en_oh = to_categorical(np.arange(0,en_vocab))\n",
    "fr_oh = to_categorical(np.arange(0, fr_vocab))\n",
    "print(en_oh.shape, fr_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function word to oh\n",
    "def word2oh(word, language='en'):\n",
    "    oh = ''\n",
    "    if language == 'en':\n",
    "        index = en_word_to_index[word]\n",
    "        oh = en_oh[index]\n",
    "    elif language =='fr':\n",
    "        index = fr_word_to_index[word]\n",
    "        oh = fr_oh[index]      \n",
    "    return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function sentence to one hot, there is \"reverse\" argument to reverse one hot encode for better model performance\n",
    "def sent2oh(sentence, language='en', reverse=False):\n",
    "    oh = list()\n",
    "    if language=='en':\n",
    "        sequence = en_token.texts_to_sequences([sentence])\n",
    "        sequence = pad_sequences(sequence, padding='post', maxlen=max_en_len) #add padding\n",
    "        if reverse == True:\n",
    "            sequence = sequence[:, ::-1]\n",
    "        for seq in sequence:\n",
    "            oh.append(en_oh[seq])\n",
    "    elif language == 'fr':\n",
    "        sequence = fr_token.texts_to_sequences([sentence])\n",
    "        sequence = pad_sequences(sequence, padding='post', maxlen=max_fr_len)\n",
    "        if reverse == True:\n",
    "            sequence = sequence[:, ::-1]\n",
    "        for seq in sequence:\n",
    "            oh.append(fr_oh[seq])     \n",
    "    return np.array(oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110288, 15, 200) (110288, 21, 342)\n"
     ]
    }
   ],
   "source": [
    "train_en_oh_rev = np.vstack([(sent2oh(sent, reverse=True)) for sent in train_df['english_sentence']])\n",
    "train_fr_oh = np.vstack([(sent2oh(sent, language='fr')) for sent in train_df['french_sentence']])\n",
    "\n",
    "print(train_en_oh_rev.shape, train_fr_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27572, 15, 200) (27572, 21, 342)\n"
     ]
    }
   ],
   "source": [
    "test_en_oh_rev = np.vstack([(sent2oh(sent, reverse=True)) for sent in test_df['english_sentence']])\n",
    "test_fr_oh = np.vstack([(sent2oh(sent, language='fr')) for sent in test_df['french_sentence']])\n",
    "\n",
    "print(test_en_oh_rev.shape, test_fr_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 15, 200)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     [(None, 200), (None, 241200      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 21, 200)      0           gru_2[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 21, 200)      241200      repeat_vector_1[0][0]            \n",
      "                                                                 gru_2[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 21, 342)      68742       gru_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 551,142\n",
      "Trainable params: 551,142\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hsize = en_vocab\n",
    "\n",
    "#encoder\n",
    "en_input = Input(shape=(max_en_len, en_vocab))\n",
    "en_gru = GRU(hsize, return_state=True)\n",
    "en_out, en_state = en_gru(en_input)\n",
    "\n",
    "#decoder\n",
    "de_input = RepeatVector(max_fr_len)(en_state)\n",
    "de_gru = GRU(hsize, return_sequences=True)\n",
    "de_out = de_gru(de_input, initial_state=en_state)\n",
    "\n",
    "#prediction layer\n",
    "de_dense_time = TimeDistributed(Dense(fr_vocab, activation='softmax'))\n",
    "de_pred = de_dense_time(de_out)\n",
    "\n",
    "#compiling the model\n",
    "nmt = Model(inputs=en_input, outputs=de_pred)\n",
    "\n",
    "#summarize model\n",
    "nmt.summary()\n",
    "\n",
    "#plot graph\n",
    "# plot_model(nmt, to_file='layout.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88230 samples, validate on 22058 samples\n",
      "Epoch 1/10\n",
      "88230/88230 [==============================] - 119s 1ms/sample - loss: 1.7778 - acc: 0.5859 - val_loss: 1.2075 - val_acc: 0.6793\n",
      "Epoch 2/10\n",
      "88230/88230 [==============================] - 134s 2ms/sample - loss: 0.9994 - acc: 0.7211 - val_loss: 0.8911 - val_acc: 0.7464\n",
      "Epoch 3/10\n",
      "88230/88230 [==============================] - 134s 2ms/sample - loss: 0.8050 - acc: 0.7675 - val_loss: 0.7424 - val_acc: 0.7853\n",
      "Epoch 4/10\n",
      "88230/88230 [==============================] - 117s 1ms/sample - loss: 0.6580 - acc: 0.8070 - val_loss: 0.5943 - val_acc: 0.8237\n",
      "Epoch 5/10\n",
      "88230/88230 [==============================] - 115s 1ms/sample - loss: 0.5356 - acc: 0.8401 - val_loss: 0.4841 - val_acc: 0.8552\n",
      "Epoch 6/10\n",
      "88230/88230 [==============================] - 117s 1ms/sample - loss: 0.4324 - acc: 0.8711 - val_loss: 0.3882 - val_acc: 0.8849\n",
      "Epoch 7/10\n",
      "88230/88230 [==============================] - 120s 1ms/sample - loss: 0.3448 - acc: 0.8983 - val_loss: 0.3487 - val_acc: 0.8984\n",
      "Epoch 8/10\n",
      "88230/88230 [==============================] - 115s 1ms/sample - loss: 0.2706 - acc: 0.9223 - val_loss: 0.2476 - val_acc: 0.9293\n",
      "Epoch 9/10\n",
      "88230/88230 [==============================] - 117s 1ms/sample - loss: 0.2179 - acc: 0.9389 - val_loss: 0.2003 - val_acc: 0.9453\n",
      "Epoch 10/10\n",
      "88230/88230 [==============================] - 117s 1ms/sample - loss: 0.1787 - acc: 0.9501 - val_loss: 0.1799 - val_acc: 0.9490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2569ef7d048>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmt.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "nmt.fit(train_en_oh_rev, train_fr_oh, batch_size=128, epochs=10, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Predict on test data or translate English sentences in test data into French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27572, 21, 342)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_fr_oh = nmt.predict(test_en_oh_rev)\n",
    "pred_fr_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to transform one hots to french sentences\n",
    "def oh2fr(ohs):\n",
    "    sequences = np.argmax(ohs, axis=-1)\n",
    "    sentences = list()\n",
    "    for seq in sequences:\n",
    "        sent = [fr_index_to_word[i] for i in seq if i != 0]\n",
    "        sent = ' '.join(sent)\n",
    "        sentences.append(sent)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fr = oh2fr(pred_fr_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 10 predictions with Frech sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentence:  france is sometimes cold during april , but it is never warm in november .\n",
      "True French sentence:  la france est parfois froid en avril , mais il est jamais chaud en novembre .\n",
      "Predicted French sentence:  la france est parfois froid en avril mais il est jamais chaud en novembre\n",
      "==========\n",
      "English sentence:  china is usually pleasant during december , and it is wet in march .\n",
      "True French sentence:  chine est généralement agréable en décembre , et il est humide en mars .\n",
      "Predicted French sentence:  chine est généralement agréable en décembre et il est humide en mars\n",
      "==========\n",
      "English sentence:  that cat was my most loved animal .\n",
      "True French sentence:  ce chat était mon animal le plus aimé .\n",
      "Predicted French sentence:  ce chat est mon animal le plus aimé\n",
      "==========\n",
      "English sentence:  china is never relaxing during may , and it is pleasant in august .\n",
      "True French sentence:  la chine est jamais relaxant au mois de mai , et il est agréable en août .\n",
      "Predicted French sentence:  la chine est jamais relaxant au mois de mai et il est agréable en août\n",
      "==========\n",
      "English sentence:  california is never wet during january , but it is never freezing in march .\n",
      "True French sentence:  california est jamais humide en janvier , mais il est jamais gelé en mars .\n",
      "Predicted French sentence:  california est jamais humide en janvier mais il gèle jamais en mars\n",
      "==========\n",
      "English sentence:  we dislike lemons and limes .\n",
      "True French sentence:  nous détestons les citrons et les citrons verts .\n",
      "Predicted French sentence:  nous détestons les citrons et les citrons verts\n",
      "==========\n",
      "English sentence:  india is usually wet during december , and it is never chilly in summer .\n",
      "True French sentence:  l' inde est généralement humide en décembre , et il est jamais froid en été .\n",
      "Predicted French sentence:  l' inde est généralement humide en décembre et il est jamais froid en été\n",
      "==========\n",
      "English sentence:  paris is sometimes pleasant during june , and it is never cold in december .\n",
      "True French sentence:  paris est parfois agréable en juin , et il ne fait jamais froid en décembre .\n",
      "Predicted French sentence:  paris est parfois agréable en juin et il ne fait jamais froid en décembre\n",
      "==========\n",
      "English sentence:  new jersey is usually nice during april , and it is usually busy in july .\n",
      "True French sentence:  new jersey est généralement agréable en avril , et il est généralement occupé en juillet .\n",
      "Predicted French sentence:  new jersey est généralement agréable en avril et il est généralement occupé en juillet\n",
      "==========\n",
      "English sentence:  paris is usually pleasant during summer , and it is usually relaxing in autumn .\n",
      "True French sentence:  paris est généralement agréable en été , et il est relaxant habituellement à l' automne .\n",
      "Predicted French sentence:  paris est généralement agréable en été et il est relaxant habituellement à l' automne\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('English sentence: ', test_df['english_sentence'].iloc[i])\n",
    "    print('True French sentence: ', test_df['french_sentence'].iloc[i])\n",
    "    print('Predicted French sentence: ', pred_fr[i])\n",
    "    print('==========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate model using BLEU score (future work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
